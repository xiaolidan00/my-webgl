<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>反射立方体</title>
    <script src="../libs/gl-matrix-min.js"></script>
    <script src="../libs/dat.gui.min.js"></script>
    <script src="../libs/utils.js"></script>
    <script src="../libs/helper.js"></script>
    <script src="./cube.js"></script>
    <style>
      #webgl,
      body {
        padding: 0;
        margin: 0;
        position: absolute;
        height: 100%;
        width: 100%;
      }
    </style>
  </head>
  <body onload="init()">
    <canvas id="webgl"></canvas>
    <script id="vertexShader" type="x-shader/x-vertex">
            attribute vec4 a_position;
      attribute vec3 a_normal;

      uniform mat4 u_projection;
      uniform mat4 u_view;
      uniform mat4 u_world;

      varying vec3 v_worldPosition;
      varying vec3 v_worldNormal;

      void main() {
        // Multiply the position by the matrix.
        gl_Position = u_projection * u_view * u_world * a_position;

        // send the view position to the fragment shader
        v_worldPosition = (u_world * a_position).xyz;

        // orient the normals and pass to the fragment shader
        v_worldNormal = mat3(u_world) * a_normal;
      }
    </script>

    <script id="fragmentShader" type="x-shader/x-fragment">
      precision highp float;

      // Passed in from the vertex shader.
      varying vec3 v_worldPosition;
      varying vec3 v_worldNormal;

      // The texture.
      uniform samplerCube u_texture;

      // The position of the camera
      uniform vec3 u_worldCameraPosition;

      void main() {
        vec3 worldNormal = normalize(v_worldNormal);
        vec3 eyeToSurfaceDir = normalize(v_worldPosition - u_worldCameraPosition);
        vec3 direction = reflect(eyeToSurfaceDir,worldNormal);

        gl_FragColor = textureCube(u_texture, direction);
      }
    </script>

    <script>
      async function init() {
        var gl = initGl('webgl');
        const vs = document.getElementById('vertexShader').innerText;

        const fs = document.getElementById('fragmentShader').innerText;

        var program = initShaderProgram(gl, vs, fs);
        // look up where the vertex data needs to go.
        var positionLocation = gl.getAttribLocation(program, 'a_position');
        var normalLocation = gl.getAttribLocation(program, 'a_normal');

        // lookup uniforms
        var projectionLocation = gl.getUniformLocation(program, 'u_projection');
        var viewLocation = gl.getUniformLocation(program, 'u_view');
        var worldLocation = gl.getUniformLocation(program, 'u_world');
        var textureLocation = gl.getUniformLocation(program, 'u_texture');
        var worldCameraPositionLocation = gl.getUniformLocation(program, 'u_worldCameraPosition');

        // Create a buffer for positions
        var positionBuffer = gl.createBuffer();
        // Bind it to ARRAY_BUFFER (think of it as ARRAY_BUFFER = positionBuffer)
        gl.bindBuffer(gl.ARRAY_BUFFER, positionBuffer);
        // Put the positions in the buffer
        setGeometry(gl);
        initArrBuffer(gl, 'aPosition', new Float32Array(flatArr(positions)), 3);
        initArrBuffer(gl, 'aNormal', new Float32Array(flatArr(normals)));

        //立方体贴图
        const images = {
          //前
          f: 'images/cube/f.jpg',
          //后
          b: 'images/cube/b.jpg',
          //上
          u: 'images/cube/u.jpg',
          //下
          d: 'images/cube/d.jpg',
          //左
          l: 'images/cube/l.jpg',
          //右
          r: 'images/cube/r.jpg'
        };

        await initCubeTexture(gl, images);
        gl.uniform1i(gl.getUniformLocation(gl.program, 'uImage'), 0);
        //透视投影
        const fieldOfView = degToRad(45);
        const aspect = gl.canvas.width / gl.canvas.height;
        const zNear = 1;
        const zFar = 2000.0;
        var projectionMatrix = mat4.create();

        mat4.perspective(projectionMatrix, fieldOfView, aspect, zNear, zFar);
        //画全景图的板面
        var settings = {
          x: 1,
          y: 0,
          z: 1
        };
        var gui = new dat.GUI();
        for (let k in settings) {
          gui.add(settings, k, -1, 1).onChange(drawScene);
        }

        function drawScene() {
          cleanGl(gl);
          //相机位置
          // convert to seconds
          time *= 0.001;
          // Subtract the previous time from the current time
          var deltaTime = time - then;
          // Remember the current time for the next frame.
          then = time;

          webglUtils.resizeCanvasToDisplaySize(gl.canvas);

          // Tell WebGL how to convert from clip space to pixels
          gl.viewport(0, 0, gl.canvas.width, gl.canvas.height);

          gl.enable(gl.CULL_FACE);
          gl.enable(gl.DEPTH_TEST);

          // Animate the rotation
          modelYRotationRadians += -0.7 * deltaTime;
          modelXRotationRadians += -0.4 * deltaTime;

          // Clear the canvas AND the depth buffer.
          gl.clear(gl.COLOR_BUFFER_BIT | gl.DEPTH_BUFFER_BIT);

          // Tell it to use our program (pair of shaders)
          gl.useProgram(program);

          // Turn on the position attribute
          gl.enableVertexAttribArray(positionLocation);

          // Bind the position buffer.
          gl.bindBuffer(gl.ARRAY_BUFFER, positionBuffer);

          // Tell the position attribute how to get data out of positionBuffer (ARRAY_BUFFER)
          var size = 3; // 3 components per iteration
          var type = gl.FLOAT; // the data is 32bit floats
          var normalize = false; // don't normalize the data
          var stride = 0; // 0 = move forward size * sizeof(type) each iteration to get the next position
          var offset = 0; // start at the beginning of the buffer
          gl.vertexAttribPointer(positionLocation, size, type, normalize, stride, offset);

          // Turn on the normal attribute
          gl.enableVertexAttribArray(normalLocation);

          // Bind the normal buffer.
          gl.bindBuffer(gl.ARRAY_BUFFER, normalBuffer);

          // Tell the attribute how to get data out of normalBuffer (ARRAY_BUFFER)
          var size = 3; // 3 components per iteration
          var type = gl.FLOAT; // the data is 32bit floating point values
          var normalize = false; // normalize the data (convert from 0-255 to 0-1)
          var stride = 0; // 0 = move forward size * sizeof(type) each iteration to get the next position
          var offset = 0; // start at the beginning of the buffer
          gl.vertexAttribPointer(normalLocation, size, type, normalize, stride, offset);

          // Compute the projection matrix
          var aspect = gl.canvas.clientWidth / gl.canvas.clientHeight;
          var projectionMatrix = m4.perspective(fieldOfViewRadians, aspect, 1, 2000);
          gl.uniformMatrix4fv(projectionLocation, false, projectionMatrix);

          var cameraPosition = [0, 0, 2];
          var target = [0, 0, 0];
          var up = [0, 1, 0];
          // Compute the camera's matrix using look at.
          var cameraMatrix = m4.lookAt(cameraPosition, target, up);

          // Make a view matrix from the camera matrix.
          var viewMatrix = m4.inverse(cameraMatrix);

          var worldMatrix = m4.xRotation(modelXRotationRadians);
          worldMatrix = m4.yRotate(worldMatrix, modelYRotationRadians);

          // Set the uniforms
          gl.uniformMatrix4fv(projectionLocation, false, projectionMatrix);
          gl.uniformMatrix4fv(viewLocation, false, viewMatrix);
          gl.uniformMatrix4fv(worldLocation, false, worldMatrix);
          gl.uniform3fv(worldCameraPositionLocation, cameraPosition);

          // Tell the shader to use texture unit 0 for u_texture
          gl.uniform1i(textureLocation, 0);

          // Draw the geometry.
          gl.drawArrays(gl.TRIANGLES, 0, vertexCount);

          requestAnimationFrame(drawScene);
        }
        drawScene();
      }
    </script>
  </body>
</html>
